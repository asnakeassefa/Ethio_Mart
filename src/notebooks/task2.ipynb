{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Channel Title Channel Username    ID  \\\n",
      "0        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6821   \n",
      "1        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6820   \n",
      "2        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6819   \n",
      "3        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6818   \n",
      "4        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6817   \n",
      "\n",
      "                                             Message  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2  ğŸ“£ ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ”  ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” \\n\\nâœ”ï¸ á‹˜áˆ˜áŠ“á‹Š á‰ áŠ¤áˆŒáŠ­á‰µáˆ®áŠ’áŠ­áˆµ á‹¨áˆšáˆ°áˆ« áˆšá‹›áŠ•\\...   \n",
      "3  ğŸ“£ ğŸ” ğŸ” ğŸ” ğŸ” ğŸ”  ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ”  ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” \\n\\nâœ”ï¸ á‰¦áˆ­áŒ­ á‹¨áˆšáˆ°á‰ áˆµá‰¥\\nâœ”ï¸á‹¨á‰¦...   \n",
      "4  ğŸ“£ Multi Functional Shoe and Hat Rack\\n\\nğŸ“ á‹­áˆ„áŠ•áŠ•...   \n",
      "\n",
      "                        Date                 Media Path  \n",
      "0  2024-09-29 15:35:04+00:00  photos/@MerttEka_6821.jpg  \n",
      "1  2024-09-29 15:35:03+00:00  photos/@MerttEka_6820.jpg  \n",
      "2  2024-09-29 15:35:03+00:00  photos/@MerttEka_6819.jpg  \n",
      "3  2024-09-29 15:13:37+00:00  photos/@MerttEka_6818.jpg  \n",
      "4  2024-09-29 14:53:49+00:00                        NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../telegram_data.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the 'Message' column:\n",
      "Number of NaN values in 'Message' column: 1559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for NaN values in the 'Message' column\n",
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = df['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4165 entries, 2 to 5710\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Channel Title     4165 non-null   object\n",
      " 1   Channel Username  4165 non-null   object\n",
      " 2   ID                4165 non-null   int64 \n",
      " 3   Message           4165 non-null   object\n",
      " 4   Date              4165 non-null   object\n",
      " 5   Media Path        3080 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 227.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop NaN values\n",
    "df = df.dropna(subset=['Message'])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping NaN values in 'Message' column: (4165, 6)\n",
      "Updated DataFrame:\n",
      "  Channel Title Channel Username    ID  \\\n",
      "2        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6819   \n",
      "3        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6818   \n",
      "4        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6817   \n",
      "5        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6816   \n",
      "6        áˆáˆ­áŒ¥ á‹•á‰ƒ        @MerttEka  6815   \n",
      "\n",
      "                                             Message  \\\n",
      "2    \\n\\n á‹˜áˆ˜áŠ“á‹Š á‰ áŠ¤áˆŒáŠ­á‰µáˆ®áŠ’áŠ­áˆµ á‹¨áˆšáˆ°áˆ« áˆšá‹›áŠ•\\náŠ¥áˆµáŠ¨ 50 áŠªáˆ á‹­áˆ˜á‹áŠ“...   \n",
      "3     \\n\\n á‰¦áˆ­áŒ­ á‹¨áˆšáˆ°á‰ áˆµá‰¥\\ná‹¨á‰¦áˆ­áŒ­ áˆµá‰¥ á‹¨áˆšá‹«á‰ƒáŒ¥áˆ \\n áˆ›áˆ«áŠª á‹¨áˆ°á‹áŠ...   \n",
      "4   Multi Functional Shoe and Hat Rack\\n\\n á‹­áˆ„áŠ•áŠ• t...   \n",
      "5   Multi Functional Shoe and Hat Rack\\n\\n á‰£áˆˆ á‹˜áˆ­áˆ...   \n",
      "6   \\n\\n Breast Shell Milk Collector\\n\\n á‹­áˆ„áŠ•áŠ• t.m...   \n",
      "\n",
      "                        Date                 Media Path  \n",
      "2  2024-09-29 15:35:03+00:00  photos/@MerttEka_6819.jpg  \n",
      "3  2024-09-29 15:13:37+00:00  photos/@MerttEka_6818.jpg  \n",
      "4  2024-09-29 14:53:49+00:00                        NaN  \n",
      "5  2024-09-29 14:50:01+00:00  photos/@MerttEka_6816.jpg  \n",
      "6  2024-09-27 18:15:44+00:00                        NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the shape of the dataset after dropping NaN values in the \"Message\" column\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to label messages with entity types\n",
    "def label_message_utf8_with_birr(message):\n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Tokenize the message\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Check if token is a price (e.g., 500 ETB, $100, or á‰¥áˆ­)\n",
    "        if re.match(r'^\\d+(\\.\\d{1,2})?$', token) or 'ETB' in token or 'á‹‹áŒ‹' in token or '$' in token or 'á‰¥áˆ­' in token:\n",
    "            labeled_tokens.append(f\"{token} B-PRICE\")  # Assuming the first price token as B-PRICE\n",
    "        # Check if token could be a location (e.g., cities or general location names)\n",
    "        elif any(loc in token for loc in ['Addis Ababa', 'áˆˆá‰¡', 'áˆˆá‰¡Â áˆ˜á‹³áˆ…áŠ’á‹“áˆˆáˆ', 'áˆ˜áŒˆáŠ“áŠ›', 'á‰¦áˆŒ', 'áˆœáŠ­áˆ²áŠ®']):\n",
    "            labeled_tokens.append(f\"{token} B-LOC\")  # Assuming the first location token as B-LOC\n",
    "        # Assume other tokens are part of a product name or general text\n",
    "        else:\n",
    "            labeled_tokens.append(f\"{token} O\")  # Outside any entity\n",
    "            \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Sample 30-50 messages for labeling\n",
    "sample_size = 30\n",
    "sample_df = df.sample(n=sample_size)\n",
    "\n",
    "# Apply the labeling function to the sampled messages\n",
    "sample_df['Labeled_Message'] = sample_df['Message'].apply(label_message_utf8_with_birr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Labeled Messages:\n",
      "                                                Message  \\\n",
      "2096                 Cosmetic and Jewellery Storage Box   \n",
      "2486                     Special Base for Refrigerators   \n",
      "1743                                      Silicon Glove   \n",
      "127   Special Base for Refrigerators\\n\\n á‹­áˆ„áŠ•áŠ• t.me/M...   \n",
      "549    Nokba Alumunium Cloth Draying RACK\\n\\n á‹¨á‰±áˆ­áŠ­ áˆ...   \n",
      "2207                              Orthopedic Leg Pillow   \n",
      "1646   Door Bottom Strip Sealer \\n\\n áŠ á‹¨áˆ­ áŠ¨á‹áŒ­ á‹ˆá‹° á‰¤á‰µ á‹...   \n",
      "5264  áˆˆáŠ¥á‹­á‰³ áˆ›áˆ«áŠª á‹¨áˆ†áŠ á‹¨áˆá‰¥áˆµ á‰áˆ áˆ³áŒ¥áŠ• áˆˆáŠ¥áˆ­áˆµá‹á£áˆˆáˆáŒ†á‰½á‹ á‹ˆá‹­áŠ•áˆ á£áˆˆá‹ˆá‹³...   \n",
      "5496  á‹¨áŠ¬áŠ­ á‹ˆá‹­áŠ•áˆ Ice cream áˆ›á‰…áˆ¨á‰¢á‹« \\ná‹¨á‰±áˆ­áŠ­ áˆµáˆªá‰µ á‹¨áˆ†áŠ á‰†áŠ•áŒ† á‹•á‰ƒ...   \n",
      "2145   Hair Drying Towel\\n\\n á‹¨á€áŒ‰áˆ­ áˆ›á‹µáˆ¨á‰‚á‹« ááŒ£\\ná‰¶áˆ á‹áˆƒ áˆ˜áˆ...   \n",
      "3590  Saachi Hot Plate\\n#orginal stove\\n# 2000watt\\n...   \n",
      "5255  Saachi á‹¨á‰¡áŠ“áŠ“ á‹¨áˆ»á‹­ áˆ˜áŒ­áˆ˜á‰‚á‹« áˆ›áŒ£áˆªá‹«áŠ“ áˆ›ááˆŠá‹« áˆ›áˆ½áŠ•á¢\\n800 á‹‹á‰µ ...   \n",
      "5239  áˆˆáŠ¥á‹­á‰³ áˆ›áˆ«áŠª á‹¨áˆ†áŠ á‹¨áˆá‰¥áˆµ á‰áˆ áˆ³áŒ¥áŠ• áˆˆáŠ¥áˆ­áˆµá‹á£áˆˆáˆáŒ†á‰½á‹ á‹ˆá‹­áŠ•áˆ á£áˆˆá‹ˆá‹³...   \n",
      "1964    áˆá‹© á‹¨áŒˆáŠ“ á‰ á‹“áˆ á‰…áŠ“áˆ½\\n\\nKITCHEN SPECIALIST MEAT AN...   \n",
      "4235  Piza Pan(GEEPERS)\\ná‹¨á’á‹› áˆ˜áŒ‹áŒˆáˆªá‹«\\n á‰µáˆá‰ áˆ³á‹­á‹ (42cm)\\...   \n",
      "341    3two ROSHAN Kids Lunch Box\\n\\n Original á‹¨áˆáˆ³ á‹•...   \n",
      "3526                                      Head Massager   \n",
      "2079   Non Stick 6pc Knife Set\\n\\n á‰¶áˆ á‹¨áˆ›á‹­á‹°áŠ•á‹™ áˆµáˆ á‹¨áˆ†áŠ‘ ...   \n",
      "1724  CHILDREN FOLDING TUB\\n\\n á‹¨áˆ…áƒáŠ“á‰³ áŒˆáˆ‹ áˆ˜á‰³áŒ á‰¢á‹« áŒˆáŠ•á‹³\\n ...   \n",
      "2616         Multifunctional Indoor Cloth Hanger/Drayer   \n",
      "4368                                 Scarlet hand mixer   \n",
      "1941    áˆá‹© á‹¨áŒˆáŠ“ á‰ á‹“áˆ á‰…áŠ“áˆ½\\n Home Decoration Essentials ...   \n",
      "3949                     LONG HANDLE DISH WASHING BRUSH   \n",
      "3660  Ice cream and fruit cap\\n á‹¨áŠ á‹­áˆµ áŠ­áˆ¬áˆ áŠ¥áŠ“ á‹¨ááˆ©á‰µ á“áŠ•á‰½...   \n",
      "1707  Nima Deep Oil Fraying \\n\\náŠ’áˆ› á‹¨á‰½á•áˆµ áˆ˜áŒ¥á‰ áˆ»\\n áŠ¥áˆµáŠ¨ 4...   \n",
      "1031   Digital Measuring Spoon\\n\\n á‹­áˆ„áŠ•áŠ• t.me/MerttEk...   \n",
      "4050  12 Set Silcon Spatulas\\n áŠ¨áá‰°áŠ› áˆ™á‰€á‰µ á‹¨áˆšá‰‹á‰‹áˆ™ \\n áŠªá‰½áŠ•...   \n",
      "4554  ICE CUBIC MAKER\\ná‹¨á‰ áˆ¨á‹¶ áˆ˜áˆµáˆªá‹«áŠ“ áˆ›á‰…áˆ¨á‰¢á‹«\\n á‰ áˆ¨á‹¶ á‰ á‰€áˆ‹áˆ‰ á‹­...   \n",
      "1412   Rechargable Water Pump\\n\\n á‹­áˆ„áŠ•áŠ• t.me/MerttEka...   \n",
      "5187  4.2 áˆŠá‰µáˆ­ á‰ áŠ áŠ•á‹µ áŒŠá‹œ á‹«áˆˆáˆáŠ•áˆ á‹˜á‹­á‰µ (0 oil) á‰ áˆ˜áŒ á‰€áˆ á‹¨áˆšá‹«á‰ áˆµáˆ...   \n",
      "\n",
      "                                        Labeled_Message  \n",
      "2096   Cosmetic O\\nand O\\nJewellery O\\nStorage O\\nBox O  \n",
      "2486          Special O\\nBase O\\nfor O\\nRefrigerators O  \n",
      "1743                                 Silicon O\\nGlove O  \n",
      "127   Special O\\nBase O\\nfor O\\nRefrigerators O\\ná‹­áˆ„áŠ•...  \n",
      "549   Nokba O\\nAlumunium O\\nCloth O\\nDraying O\\nRACK...  \n",
      "2207                      Orthopedic O\\nLeg O\\nPillow O  \n",
      "1646  Door O\\nBottom O\\nStrip O\\nSealer O\\náŠ á‹¨áˆ­ O\\náŠ¨á‹...  \n",
      "5264  áˆˆáŠ¥á‹­á‰³ O\\náˆ›áˆ«áŠª O\\ná‹¨áˆ†áŠ O\\ná‹¨áˆá‰¥áˆµ O\\ná‰áˆ O\\náˆ³áŒ¥áŠ• O\\náˆˆáŠ¥áˆ­...  \n",
      "5496  á‹¨áŠ¬áŠ­ O\\ná‹ˆá‹­áŠ•áˆ O\\nIce O\\ncream O\\náˆ›á‰…áˆ¨á‰¢á‹« O\\ná‹¨á‰±áˆ­áŠ­ O...  \n",
      "2145  Hair O\\nDrying O\\nTowel O\\ná‹¨á€áŒ‰áˆ­ O\\náˆ›á‹µáˆ¨á‰‚á‹« O\\nááŒ£...  \n",
      "3590  Saachi O\\nHot O\\nPlate O\\n#orginal O\\nstove O\\...  \n",
      "5255  Saachi O\\ná‹¨á‰¡áŠ“áŠ“ O\\ná‹¨áˆ»á‹­ O\\náˆ˜áŒ­áˆ˜á‰‚á‹« O\\náˆ›áŒ£áˆªá‹«áŠ“ O\\náˆ›ááˆŠ...  \n",
      "5239  áˆˆáŠ¥á‹­á‰³ O\\náˆ›áˆ«áŠª O\\ná‹¨áˆ†áŠ O\\ná‹¨áˆá‰¥áˆµ O\\ná‰áˆ O\\náˆ³áŒ¥áŠ• O\\náˆˆáŠ¥áˆ­...  \n",
      "1964  áˆá‹© O\\ná‹¨áŒˆáŠ“ O\\ná‰ á‹“áˆ O\\ná‰…áŠ“áˆ½ O\\nKITCHEN O\\nSPECIALI...  \n",
      "4235  Piza O\\nPan(GEEPERS) O\\ná‹¨á’á‹› O\\náˆ˜áŒ‹áŒˆáˆªá‹« O\\ná‰µáˆá‰ O\\...  \n",
      "341   3two O\\nROSHAN O\\nKids O\\nLunch O\\nBox O\\nOrig...  \n",
      "3526                                 Head O\\nMassager O  \n",
      "2079  Non O\\nStick O\\n6pc O\\nKnife O\\nSet O\\ná‰¶áˆ O\\ná‹¨...  \n",
      "1724  CHILDREN O\\nFOLDING O\\nTUB O\\ná‹¨áˆ…áƒáŠ“á‰³ O\\náŒˆáˆ‹ O\\náˆ˜...  \n",
      "2616  Multifunctional O\\nIndoor O\\nCloth O\\nHanger/D...  \n",
      "4368                         Scarlet O\\nhand O\\nmixer O  \n",
      "1941  áˆá‹© O\\ná‹¨áŒˆáŠ“ O\\ná‰ á‹“áˆ O\\ná‰…áŠ“áˆ½ O\\nHome O\\nDecoration ...  \n",
      "3949       LONG O\\nHANDLE O\\nDISH O\\nWASHING O\\nBRUSH O  \n",
      "3660  Ice O\\ncream O\\nand O\\nfruit O\\ncap O\\ná‹¨áŠ á‹­áˆµ O\\...  \n",
      "1707  Nima O\\nDeep O\\nOil O\\nFraying O\\náŠ’áˆ› O\\ná‹¨á‰½á•áˆµ O...  \n",
      "1031  Digital O\\nMeasuring O\\nSpoon O\\ná‹­áˆ„áŠ•áŠ• O\\nt.me/...  \n",
      "4050  12 B-PRICE\\nSet O\\nSilcon O\\nSpatulas O\\náŠ¨áá‰°áŠ› ...  \n",
      "4554  ICE O\\nCUBIC O\\nMAKER O\\ná‹¨á‰ áˆ¨á‹¶ O\\náˆ˜áˆµáˆªá‹«áŠ“ O\\náˆ›á‰…áˆ¨á‰¢...  \n",
      "1412  Rechargable O\\nWater O\\nPump O\\ná‹­áˆ„áŠ•áŠ• O\\nt.me/M...  \n",
      "5187  4.2 B-PRICE\\náˆŠá‰µáˆ­ O\\ná‰ áŠ áŠ•á‹µ O\\náŒŠá‹œ O\\ná‹«áˆˆáˆáŠ•áˆ O\\ná‹˜á‹­á‰µ...  \n",
      "Labeled data saved to labeled_telegram_product_price_location.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the labeled messages\n",
    "print(\"Sampled Labeled Messages:\")\n",
    "print(sample_df[['Message', 'Labeled_Message']])\n",
    "\n",
    "# Save the labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = 'labeled_telegram_product_price_location.txt'\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in sample_df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")\n",
    "\n",
    "print(f\"Labeled data saved to {labeled_data_birr_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
